# Learning-Group-Actions-In-Disentangled-Latent-Image-Representations

## Abstract
Modeling group actions on latent representations enables controllable transformations of high-dimensional image data. Prior works applying group-theoretic priors or modeling transformations typically operate in the high-dimensional data space, where group actions apply uniformly across the entire input, making it difficult to disentangle the subspace that varies under transformations. While latent-space methods offer greater flexibility, they still require manual partitioning of latent variables into equivariant and invariant subspaces, limiting the ability to robustly learn and operate group actions within the latent space. To address this, we introduce a novel end-to-end framework that learns group actions on latent image manifolds through differentiable channel masking, automatically discovering transformation-relevant structures without manual intervention. We formulate this within a unified optimization framework that jointly learns latent disentanglement and group transformation mappings. Our method employs learnable binary masks with straight-through estimation to dynamically partition latent channels into transformation-sensitive and invariant components during training. The framework integrates seamlessly with any standard encoder-decoder architecture. We validate our approach on six 2D/3D image datasets, demonstrating its ability to automatically learn disentangled latent factors, while downstream classification tasks confirm the effectiveness of the learned representations.
